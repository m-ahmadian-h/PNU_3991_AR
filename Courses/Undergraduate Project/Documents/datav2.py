# -*- coding: utf-8 -*-
"""datav2.2.netherlands.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k8QB_bRK2YOqcF2qGncnEal6cgx-Y3_0
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
from google.colab import drive
import numpy as np
import tensorflow.keras as ks
import timeit
#!pip install tpucolab
#import os
#import google as gg
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
import matplotlib.pyplot as plt
#from multiprocessing import Pool
#import time
#from tensorflow.keras.models import load_model
#import zipfile
#import pprint
#from tpucolab import *
from tensorflow.python.client import device_lib
#!cat /proc/meminfo
#!cat /proc/cpuinfo
#!pip install --upgrade tensorflow
#print('>>> tensorflow version: ***',tf.__version__,'***')
print(device_lib.list_local_devices())

def gpu():
  for i in range(100):
    with tf.device('/device:GPU:0'):
      random_image_gpu = tf.random.normal((50, 50, 50, 3))
      net_gpu = tf.keras.layers.Conv2D(8, 7)(random_image_gpu)
      net_gpu = tf.keras.layers.Conv2D(8, 7)(random_image_gpu)
      return tf.math.reduce_sum(net_gpu)
speed =int(1/(timeit.timeit('gpu()', number=10, setup="from __main__ import gpu"))*100)/100
print('speed=',speed,'x')

drive.mount('/content/gdrive')
!unzip "/content/gdrive/My Drive/data.zip"
data=np.loadtxt('data.csv',delimiter=',',dtype='float32')



plt.plot(data[:,0])

data.shape

data[0]

s=55
datainput=np.zeros((data.shape[0]-991,18,s),dtype='float32')
f=np.zeros((data.shape[0]-991,1),dtype='float32')
for i in range(datainput.shape[0]):
  f[i]=data[i+s-1,0]/100
  for j in range(18):
    datainput[i,j,:]=data[i:i+s,j+1]

x=10230
print(datainput[x,0])
print(f[x])

data2=[]
f2=[]
for i in range(datainput.shape[0]):
  if f[i]!=9.99 and f[i]<=1 and f[i]>=0 and datainput[i,0,0]!=999:
    data2.append(datainput[i])
    f2.append(f[i])

data2=np.array(data2,dtype='float32')
f2=np.array(f2,dtype='float32')

data2.shape

f2.shape

f2[:]=(f2[:]-min(f2[:]))/(max(f2[:])-min(f2[:]))

plt.plot(f2)

for i in range(data2.shape[0]):
  for j in range(data2.shape[1]):
    data2[:,i]=(data2[:,i]-min(data2[:,i]))/(max(data2[:,i])-min(data2[:,i]))

x=10230
print(data2[x,0])
print(f2[x])

data2=data2.reshape(data2.shape[0],data2.shape[2],data2.shape[1])

datax=data2[:,:,:]
datay=f2[:]
datay_v2=np.zeros( (datay.shape[0] , 2) ,dtype='float32')
#--------------------------------------------------------
for i in range(datay.shape[0]):
  datay_v2[i,0]=datay[i]
  datay_v2[i,1]=abs(datay[i]-1)
#---------------------------------------------------------------------------------
datax_train=np.zeros( ( 170000 , datax.shape[1],datax.shape[2]) ,dtype='float32')
datax_test=np.zeros( ( 43978 , datax.shape[1],datax.shape[2]) ,dtype='float32')

datay_train=np.zeros(( datax_train.shape[0] , 2 ),dtype='float32') 
datay_test=np.zeros(( datax_test.shape[0] , 2 ) ,dtype='float32')

datax_test=datax[0:datax_test.shape[0]]
datax_train=datax[datax_test.shape[0]:]

datay_test=datay_v2[0:datay_test.shape[0],:]
datay_train=datay_v2[datay_test.shape[0]:,:]

plt.plot(datax_test[900,17,:])

datay_test[2]

inputlayer=tf.keras.layers.Input(shape=(s,18))#,activation='softplus'
layer=tf.keras.layers.LSTM(100,return_sequences=True)(inputlayer)
layer=tf.keras.layers.Dropout(0.2)(layer)
layer=tf.keras.layers.LSTM(100,return_sequences=True)(layer)
layer=tf.keras.layers.LSTM(100)(layer)
layer=tf.keras.layers.Dropout(0.2)(layer)
layer=tf.keras.layers.Dense(2,activation='softmax')(layer)
model=tf.keras.Model(inputlayer,layer)
model.summary()
#ks.utils.plot_model(model, show_shapes=True, show_layer_names=False, dpi=75)
#-------------------------------------------------------------------------------------------
model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.mse,metrics=['acc'])
drive.mount('/content/gdrive')
'''
model.load_weights('/content/gdrive/My Drive/datav2.2.h5')
x=!cat /content/gdrive/My\ Drive/number.2.txt
z=2
c=70000
x=int(x[0])+z
y=int(speed/x*c)
print("data trained: ",x-z)
print("data for train: ",y)
print("data version: ",z)
'''

x=!cat /content/gdrive/My\ Drive/number.2.txt
x=int(x[0])+z
y=int(speed/x*c)
print(" data trained: ",x-z,'\n',"data for train: ",y,'\n',"data version: ",z,'\n')
for i in range(x,x+y*z,z):
  history=model.fit(datax_train[:i,:],datay_train[:i,:],batch_size=1)#, epochs=1,validation_data=(datax_test,datay_test)
  model.save_weights('/content/gdrive/My Drive/datav2.2.h5')
  i=str(i)
  with open('/content/gdrive/My Drive/number.2.txt', 'w') as f:
    f.write(i)

x=!cat /content/gdrive/My\ Drive/number.2.txt
x=int(x[0])+z
y=int(speed/x*c)
print(" data trained: ",x-z,'\n',"data for train: ",y,'\n',"data version: ",z,'\n')
for i in range(x,x+y*z,z):
  history=model.fit(datax_train[:i,:],datay_train[:i,:],batch_size=1)#, epochs=1,validation_data=(datax_test,datay_test)
  model.save_weights('/content/gdrive/My Drive/datav2.2.h5')
  i=str(i)
  with open('/content/gdrive/My Drive/number.2.txt', 'w') as f:
    f.write(i)